{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de datos Experimento 1\n",
    "Con 10% de hábitat en el paisaje, 10 niveles de intensificación y 100 comunidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn, math, os\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "seaborn.set_palette(\"deep\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run medidas_biodiversidad.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones para leer datos, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leer_datos(het):\n",
    "    files = os.listdir(\"./datos/exp1\")\n",
    "    files.sort()\n",
    "    files = list(filter(lambda x: x[6] == het, files))\n",
    "    \n",
    "    datos = [np.load(\"./datos/exp1/\" + file) for file in files]\n",
    "    comunidad = [file[9:12] for file in files]\n",
    "    \n",
    "    return datos, comunidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcular_medida(medida, datos, paisajes, bio_min = 5.):\n",
    "    medidas = np.zeros((100, 10))\n",
    "    for comunidad in range(len(datos)):\n",
    "        for intensificacion in range(len(datos[0])):\n",
    "            medidas[comunidad, intensificacion] = medida(\n",
    "                                                    datos[comunidad][intensificacion], \n",
    "                                                    paisajes[intensificacion],\n",
    "                                                    t=-2, biomasa_min = bio_min)\n",
    "    return medidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcular_riqueza(datos, paisajes, bio_min = 5.):\n",
    "    riquezas = np.zeros((100, 10))\n",
    "    biomasas = np.zeros((100, 10))\n",
    "\n",
    "    for comunidad in range(len(datos)):\n",
    "        for intensificacion in range(len(datos[0])):\n",
    "            biomasas[comunidad, intensificacion], riquezas[comunidad, intensificacion] = riqueza_agricola(\n",
    "                                                    datos[comunidad][intensificacion], \n",
    "                                                    paisajes[intensificacion],\n",
    "                                                    t=-2, biomasa_min = bio_min)\n",
    "    return biomasas, riquezas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcular_riquezatotal(datos, bio_min = 5.):\n",
    "    riquezas = np.zeros((100, 10))\n",
    "    for comunidad in range(len(datos)):\n",
    "        for intensificacion in range(len(datos[0])):\n",
    "            riquezas[comunidad, intensificacion] = riqueza_paisaje(\n",
    "                                                    datos[comunidad][intensificacion],\n",
    "                                                    t=-2, biomasa_min = bio_min)[1]\n",
    "    return riquezas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcular_promedio(riquezas):\n",
    "    \"\"\"Recibe datos de riqueza.\n",
    "    \"\"\"\n",
    "    promedios = np.zeros(10)\n",
    "    std = np.zeros(10)\n",
    "    for i in range(10):\n",
    "        promedios[i] = np.mean(riquezas[riquezas[:, 0]>=0, i])\n",
    "        std[i] = np.std(riquezas[:, i])\n",
    "    return promedios, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer datos, calcular promedios, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paisajes = [None] * 5\n",
    "for het in range(5):\n",
    "    paisajes[het] = np.load(\"paisajes_h{}.npy\".format(het))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0a238930c691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhet\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleer_datos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbiomasas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mriquezas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhet\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcular_riqueza\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaisajes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbio_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-bdc44d968a8e>\u001b[0m in \u001b[0;36mleer_datos\u001b[0;34m(het)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdatos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./datos/exp1/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcomunidad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-bdc44d968a8e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdatos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./datos/exp1/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcomunidad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ireneramos/miniconda3/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0m_ZIP_PREFIX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PK\\x03\\x04'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# back-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ZIP_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datos = [None] * 5\n",
    "riquezas = [None] * 5\n",
    "biomasas = [None] * 5\n",
    "riquezas_mean = [None] * 5\n",
    "riquezas_sd = [None] * 5\n",
    "biomasas_mean = [None] * 5\n",
    "biomasas_sd = [None] * 5\n",
    "\n",
    "prueba = [None] * 5\n",
    "prueba_mean = [None] * 5\n",
    "prueba_sd = [None] * 5\n",
    "\n",
    "for het in range(5):\n",
    "    datos[het] = leer_datos(str(het))[0]\n",
    "    \n",
    "    biomasas[het], riquezas[het] = calcular_riqueza(datos[het], paisajes[het], bio_min = 15)\n",
    "\n",
    "    riquezas_mean[het], riquezas_sd[het] = calcular_promedio(riquezas[het])\n",
    "\n",
    "    prueba[het] = calcular_medida(medida_prueba,  datos[het], paisajes[het], bio_min = 15)\n",
    "    prueba_mean[het], prueba_sd[het] = calcular_promedio(prueba[het])\n",
    "    \n",
    "    biomasas_mean[het], biomasas_sd[het] = calcular_promedio(biomasas[het])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2ad1c00f1f16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mriquezatotal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhet\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcular_riquezatotal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbio_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mriquezatotal_mean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mriquezatotal_sd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhet\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcular_promedio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mriquezatotal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-fbbd8c57192c>\u001b[0m in \u001b[0;36mcalcular_riquezatotal\u001b[0;34m(datos, bio_min)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalcular_riquezatotal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbio_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mriquezas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mcomunidad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mintensificacion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             riquezas[comunidad, intensificacion] = riqueza_paisaje(\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "riquezatotal = [None] * 5\n",
    "riquezatotal_mean = [None] * 5\n",
    "riquezatotal_sd = [None] * 5\n",
    "\n",
    "for het in range(5):\n",
    "    riquezatotal[het] = calcular_riquezatotal(datos[het], bio_min = 15)\n",
    "    riquezatotal_mean[het], riquezatotal_sd[het] = calcular_promedio(riquezatotal[het])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def graficar(medida, promedios, sd):\n",
    "    \"\"\"Graficar promedios de una medida de biodiversidad con curva ajustada ponderada\n",
    "    \"\"\"\n",
    "    y = [None] * 5\n",
    "    res = [None] * 5\n",
    "    p = [None] * 5\n",
    "    r2 = [None] * 5\n",
    "\n",
    "    x = np.linspace(0, 9, 100)\n",
    "    xdata = np.array(range(10))\n",
    "    xlabels = np.array(range(10)) * 10 \n",
    "\n",
    "    puntos = [\"o\", \"p\", \"d\", \"v\", \"s\"]\n",
    "    colors = [\"b\", 'g', 'r', 'purple', 'y']\n",
    "\n",
    "    for het in range(5):\n",
    "        res[het] = np.polyfit(xdata, promedios[het], 2, w=1/(sd[het])**2)\n",
    "        p[het] = np.poly1d(res[het])\n",
    "        r2[het] = 1 - ((np.sum((p[het](range(10)) - promedios[het])**2)) / (np.sum((promedios[het] - np.mean(promedios[het]))**2)))\n",
    "        \n",
    "    fig = plt.figure(figsize=(9, 7), dpi = 50)\n",
    "\n",
    "    for het in range(0, 5):\n",
    "        y[het] = p[het](x)\n",
    "        plt.plot(xdata, promedios[het], 'o', color= colors[het]) #data points\n",
    "        plt.plot(x, y[het], lw = 3, color= colors[het], \n",
    "                 label='{} \\n $y = {:+.3f} x^2 {:+.3f} x {:+.3f}$ \\n $R^2={:.4f}$ '.format(\n",
    "                 het, float(p[het][2]), float(p[het][1]), float(p[het][0]), float(r2[het]))) #fit\n",
    "\n",
    "    plt.ylim(-0.05)\n",
    "    plt.xlim(-0.1, 9.1)\n",
    "    plt.xticks(xdata, xlabels)\n",
    "    plt.xlabel(\"% low quality patches\", size = 15)\n",
    "    plt.ylabel(medida, size = 15)\n",
    "    plt.title(\"{} decline in landscapes with different heterogeneity\".format(medida), size = 15)\n",
    "\n",
    "    plt.legend(loc='center left', fontsize = \"large\", title=\"heterogeneity\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def graficar_violin(medida, datos, promedios, sd):\n",
    "    \"\"\"Graficar datos con violin plot\n",
    "    \"\"\"\n",
    "    y = [None] * 5\n",
    "    res = [None] * 5\n",
    "    p = [None] * 5\n",
    "    r2 = [None] * 5\n",
    "\n",
    "    x = np.linspace(0, 9, 100)\n",
    "    xdata = np.array(range(10))\n",
    "    xlabels = np.array(range(10)) * 10 \n",
    "\n",
    "    puntos = [\"o\", \"p\", \"d\", \"v\", \"s\"]\n",
    "    colors = [\"b\", 'g', 'r', 'purple', 'y']\n",
    "\n",
    "    for het in [4]:\n",
    "        res[het] = np.polyfit(xdata, promedios[het], 2, w=1/(sd[het])**2)\n",
    "        p[het] = np.poly1d(res[het])\n",
    "        r2[het] = 1 - ((np.sum((p[het](range(10)) - promedios[het])**2)) / (np.sum((promedios[het] - np.mean(promedios[het]))**2)))\n",
    "        \n",
    "    fig = plt.figure(figsize=(9, 7), dpi = 100)\n",
    "\n",
    "    for het in [4]:\n",
    "            y[het] = p[het](x)\n",
    "            plt.plot(x, y[het], lw = 3, color= colors[het], \n",
    "                    label='{} \\n $y = {:+.3f} x^2 {:+.3f} x {:+.3f}$ \\n $R^2={:.4f}$ '.format(\n",
    "                    het, float(p[het][2]), float(p[het][1]), float(p[het][0]), float(r2[het]))) #fit\n",
    "            plt.violinplot(datos[het, :, :], xdata, showmedians=True, showextrema=False, showmeans=True) #data points\n",
    "\n",
    "    plt.ylim(-0.05)\n",
    "    plt.xlim(-0.1, 9.1)\n",
    "    plt.xticks(xdata, xlabels)\n",
    "    plt.xlabel(\"% low quality patches\", size = 15)\n",
    "    plt.ylabel(medida, size = 15)\n",
    "    plt.title(\"{} decline in landscapes with different heterogeneity\".format(medida), size = 15)\n",
    "\n",
    "    plt.legend(loc='center left', fontsize = \"large\", title=\"heterogeneity\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo se distribuyen los datos? De esto dependen las pruebas de hipótesis que se hacen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graficar_violin('Richness', np.array(riquezas), riquezas_mean, riquezas_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graficar('Species richness', riquezas_mean, riquezas_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Species richness declines as a concave down curve as matrix quality decreases, in all heterogeneity levels.**\n",
    "For each heterogeneity level we fit a second degree polynomial to average species richness using the least-squares method. Following González et al. (2016), we take the quadratic term coefficient as qualitative evidence to characterize the shape of the curves: a negative coefficient indicates that biodiversity decreases as a concave down curve, while a positive coefficient indicates it decreases as a concave up curve. \n",
    "The fitted equations are:\n",
    "\n",
    "Given that the coefficient of the quadratic term of all fitted polynomials is negative, richness declines as a concave down curve in all heterogeneity levels. \n",
    "\n",
    "=> Richness is robust in high quality agricultural landscapes\n",
    "\n",
    "2. **As matrix quality decreases, richness remains higher in high heterogeneity landscapes than in low heterogeneity landscapes.**\n",
    "\n",
    "    * High heterogeneity landscapes (levels $h_4$, $h_3$ and $h_2$) have similar richness at each degree of intensification, respectively. \n",
    "    \n",
    "    We computed a KW test (non parametric version of Anova) for at each level of intensification to \n",
    "    At each level of intensification we tested the null hypothesis that the computed the Kruskal-Wallis test to \n",
    "    We use Kruskal test to identify significant differences in biodiversity between heterogeneity levels at each level of intensification. Null hypothesis is that population medians are equal.\n",
    "    \n",
    "    \n",
    "    * There is a significant difference in richness between landscapes at the two extremes of heterogenity (level $h_4$ compared with level $h_0$), along the intensification gradient.\n",
    "    * The effect of heterogeneity on richness becomes more noticeable as matrix quality decreases. \n",
    "\n",
    "3. **Our results were sensitive to the species survival threshold.**\n",
    "However, richness preserved a concave down curve at increasing orders of magnitude (from 0.0001 to 100), even if there was not a significant difference between heterogeneity levels at some of those values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading \"Using optimization methods...\". The authors discuss:\n",
    "\"...in real-world landscapes, a combination of both sharing and sparing strategies is likely needed... Our results can thus be seen as a theoretical example supporting this assertion.\"\n",
    "\n",
    "How do we contextualize our results within this argument?? ie basically we are reframing the sharing-sparing debate to account for the compound effect of landscape quality and heterogeneity. Another important property of our model is that we adopt a landscape perspective instead of focusing on a per-patch perspective?? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods\n",
    "\n",
    "We simulate landscapes with a lattice of 10 by 10 cells with periodic boundary. Each cell represents one patch of either habitat, biodiversity friendly / high quality / low intensity agriculture or biodiversity unfriendly / low quality / high intensity agriculture, and may be occupied by a community, that is, by interacting populations of multiple species. We define the quality of the landscape as the proportion of biodiversity friendly patches. Thus we model the decrease of landscape quality by increasing the proportion of biodiversity unfriendly patches. (//clarify difference between cells / patches)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion\n",
    "We adapt the model derived by González et al. to study the combined effect of landscape quality and heterogeneity on species richness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graficar('Biomass', biomasas_mean, biomasas_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué es importante considerar la distribución espacial de los individuos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graficar('Species richness (area)', prueba_mean, prueba_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "**Requiring that species occupy a minimum landscape area as an additional constraint for their survival stressed the effects of heterogeneity on biodiversity.**\n",
    "\n",
    "    * In low heterogeneity landscapes (levels $h_1$ and $h_0$) richness declines as a concave up curve with decreasing matrix quality; in contrast, richness follows a concave down curve in high heterogeneity landscapes (levels $h_4$, $h_3$ and $h_2$). \n",
    "\n",
    "    Under a stricter survival threshold, richness is robust in high heterogeneity landscapes, but it declines drastically with decreasing matrix quality in low heterogeneity landscapes.\n",
    "\n",
    "    * Again, richness higher with higher het and no difference between higher het levels. \n",
    "\n",
    "    * In this case, the effect of heterogeneity on richness is more noticeable at intermediate quality landscapes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falta el experimento control: ¿qué riqueza alcanzan las comunidades cuando no se considera la dinámica espacial, etc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graficar('riqueza total', riquezatotal_mean, riquezatotal_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "riquezatotal_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los puntos más fuertes del modelo son: uso de redes; calidad del manejo, no sólo pérdida de hábitat; ubicarlo en un contexto de conservación. \n",
    "\n",
    "Las debilidades: no utilizamos un algoritmo para crear el paisaje, por lo que no podemos controlar parámetros de % hábitat o heterogeneidad/fragmentación; la escala espacial / temporal; 'identidad' de los nodos (M sugiere que para un trabajo posterior se podrían asignar diferentes parámetros de dispersión dependiendo del nivel trófico -- para esto, revisar artículo que compara la supervivencia de diferentes perfiles de especies, que de hecho (creo que es ese) también considera tres tipos de parche (¿cómo miden la calidad de los parches?)).\n",
    "\n",
    "Preguntas: ¿dependen estas curvas de la cantidad de hábitat? Hacer simulaciones con 70% de hábitat, aunque pensar sobre cómo medir la heterogeneidad. Y revisar ese artículo que discute los niveles de fragmentación donde importa más el manejo. No debemos saturar el texto con información redundante, así que creo que sería conveniente centrarnos en paisajes altamente fragmentados. Los resultados con mayores % hábitat quizá mencionarlo como otra prueba de robustez?? \n",
    "También habíamos considerado hacer simulaciones para comparar cómo decae la riqueza conforme se pierde el hábitat, aquí sólo habría dos tipos de parche: hábitat-no hábitat y el objetivo sería comparar nuestro modelo con alguno de los otros, en especial con el que modela la pérdida de hábitat + heterogeneidad en Brasil; replicar resultados de otros es una forma de validación del modelo... pensar al respecto. También: considerar medidas de biodiversidad que consideren la distribución espacial. ¿Cómo argumentar la continuación? \n",
    "\n",
    "Para la próxima semana: análisis de sensibilidad de umbral - los patrones que se observan en las curvas (con nivel bio_min = 10 -- parece que es el que usaré) surgen conforme aumenta ese umbral y se mantienen en el rango... por lo menos hasta bio_min = 15. Probar con crecientes órdenes de magnitud. \n",
    "\n",
    "¿Qué otros parámetros podrían ser sensibles en el modelo? O que es lo mismo, ¿cuáles son nuestras suposiciones más delicadas que no tienen un sustento biológico/ecológico, que sólo son suposiciones 'numéricas'? Esto es diferente a las debilidades del modelo. Umbral de biomasa min; cantidad de iteraciones entre migración-muerte; las medidas de riqueza se toman como la mediana de la última iteración (se tendría que justificar por qué no el promedio...); la medida de heterogeneidad del paisaje y que fueron creados manualmente; las pruebas estadísticas son básicas y ahora que ya no estamos probando directamente las dos hipótesis no hay una razón para ajustar polinomio cuadrático excepto por continuación del trabajo ya publicado. \n",
    "\n",
    "Revisar en el artículo más reciente: redes solo surgen a nivel del paisaje. \n",
    "\n",
    "Dónde se ubican los paisajes que se asocian a una u otra estrategia de conservación --> aquí es donde incluiríamos el debate sharing-sparing\n",
    "\n",
    "¿Cómo concluir? Podríamos sugerir comparar comunidades: ¿una misma comunidad cambia la forma en que decae su riqueza dependiendo del nivel de heterogeneidad del paisaje donde se encuentre? Quizá la mayoría de las comunidades mantienen la forma de la curva, pero con riqueza decreciente; quizá existan comunidades más sensibles que presenten una transición de decaimiento cóncavo hacia arriba -> cóncavo hacia abajo; quizá la mayoría presentan un decaimiento sigmoidal y cambia el umbral de intensificación en el que decaen abruptamente. \n",
    "\n",
    "Recordar: por qué interesan patrones generales - difícil encontrar datos para todas las regiones donde también se presenta este fenómeno, tanto de uso de suelo como de las comunidades que los habitan. Falta una referencia acerca de que actividades agrícolas producen distintos patrones de heterogeneidad y sería valioso citar una referencia local. El enfoque teórico nos permite comparar fácilmente diferentes medidas de biodiversidad: es necesario considerar la distribución geográfica.\n",
    "\n",
    "Fin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificar diferencias significativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: shape of `np.array(biodiversity_measure)` is `[heterogeneity, communities, intensification]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do data distribute normally?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Shapiro-Wilk test. Null hypothesis is that data subset came from a normally distributed population.\n",
    "\n",
    "**Result:** Data subsets don't follow a normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for het in range(5):\n",
    "    for i in range(10):\n",
    "        res = 'normal'\n",
    "        \n",
    "        data = np.array(riquezas)[het, :, i]\n",
    "        \n",
    "        pvalue = stats.shapiro(data)[1]\n",
    "        if pvalue <= 0.05:\n",
    "            res = '---NOT NORMAL---'\n",
    "        print('H{}, i{}, p= {:.4f}, {}'.format(het, i, pvalue, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do data have the same variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Levene test, which does not assume normality. Null hypothesis is that population variances are equal. In particular, we want to know whether data subsets from all heterogeneity levels have the same variance at each intensification level.\n",
    "\n",
    "**Result:** At each intensification level, subsets from all heterogeneity levels have equal variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    equal_std = 'equal std'\n",
    "    pvalue = stats.levene(np.array(riquezas)[0, :, i],\n",
    "                          np.array(riquezas)[1, :, i],\n",
    "                          np.array(riquezas)[2, :, i],\n",
    "                          np.array(riquezas)[3, :, i],\n",
    "                          np.array(riquezas)[4, :, i], center='median')[1]\n",
    "    if pvalue <=0.05:\n",
    "        equal_std = '---std NOT EQUAL---'\n",
    "    print('i{}, pvalue={:.3f}, {}'.format(i, pvalue, equal_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences between heterogeneity levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Kruskal test to identify significant differences in biodiversity between heterogeneity levels at each level of intensification. Null hypothesis is that population medians are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no significant difference between heterogeneity levels 4, 3 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Richness\n",
    "for i in range(10):\n",
    "    res = 'no difference'\n",
    "    pvalue = stats.kruskal(np.array(riquezas)[4, :, i],\n",
    "                           np.array(riquezas)[3, :, i],\n",
    "                           np.array(riquezas)[2, :, i])[1]\n",
    "    if pvalue <=0.05:\n",
    "        res = '---DIFFERENT---'\n",
    "    print('i{}, pvalue={:.4f}, {}'.format(i, pvalue, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Area\n",
    "for i in range(10):\n",
    "    res = 'no difference'\n",
    "    pvalue = stats.kruskal(np.array(prueba)[4, :, i],\n",
    "                           np.array(prueba)[3, :, i],\n",
    "                           np.array(prueba)[2, :, i])[1]\n",
    "    if pvalue <=0.05:\n",
    "        res = '---DIFFERENT---'\n",
    "    print('i{}, pvalue={:.4f}, {}'.format(i, pvalue, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heterogeneity levels 4 (highest) and 0 (lowest) are significantly different at all intensification levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Richness\n",
    "for i in range(10):\n",
    "    res = 'no difference'\n",
    "    pvalue = stats.kruskal(np.array(riquezas)[4, :, i],\n",
    "                           np.array(riquezas)[0, :, i])[1]\n",
    "    if pvalue <=0.05:\n",
    "        res = '---DIFFERENT---'\n",
    "    print('i{}, pvalue={:.4f}, {}'.format(i, pvalue, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Area\n",
    "for i in range(10):\n",
    "    res = 'no difference'\n",
    "    pvalue = stats.kruskal(np.array(prueba)[4, :, i],\n",
    "                           np.array(prueba)[0, :, i])[1]\n",
    "    if pvalue <=0.05:\n",
    "        res = '---DIFFERENT---'\n",
    "    print('i{}, pvalue={:.4f}, {}'.format(i, pvalue, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Richness\n",
    "for i in range(10):\n",
    "    res = 'no difference'\n",
    "    pvalue = stats.f_oneway(np.array(riquezas)[4, :, i],\n",
    "                            np.array(riquezas)[0, :, i])[1]\n",
    "    if pvalue <=0.05:\n",
    "        res = '---DIFFERENT---'\n",
    "    print('i{}, pvalue={:.4f}, {}'.format(i, pvalue, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At what intensification levels are heterogeneity levels 4, 1 and 0 different from each other? ie At what intensification levels is het1 different from het4 and from het0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Richness\n",
    "for i in range(10):\n",
    "    res = '-'\n",
    "    pvalue_14 = stats.kruskal(np.array(riquezas)[4, :, i],\n",
    "                               np.array(riquezas)[1, :, i])[1]\n",
    "    \n",
    "    pvalue_10 = stats.kruskal(np.array(riquezas)[0, :, i],\n",
    "                               np.array(riquezas)[1, :, i])[1]\n",
    "    if pvalue_14 <=0.05 and pvalue_10 <= 0.05:\n",
    "        res = '---DIFFERENT---'\n",
    "    print('i{}, pvalue_14={:.4f}, pvalue_10={:.4f}, {}'.format(i, pvalue_14, pvalue_10, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Area\n",
    "for i in range(10):\n",
    "    res = '-'\n",
    "    pvalue_14 = stats.kruskal(np.array(prueba)[4, :, i],\n",
    "                               np.array(prueba)[1, :, i])[1]\n",
    "    \n",
    "    pvalue_10 = stats.kruskal(np.array(prueba)[0, :, i],\n",
    "                               np.array(prueba)[1, :, i])[1]\n",
    "    if pvalue_14 <=0.05 and pvalue_10 <= 0.05:\n",
    "        res = '---DIFFERENT---'\n",
    "    print('i{}, pvalue_14={:.4f}, pvalue_10={:.4f}, {}'.format(i, pvalue_14, pvalue_10, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiero saber si para un mismo nivel de het, los datos de todos los niveles de intensificación tienen la misma std\n",
    "for het in range(5):\n",
    "    equal_std = 'equal std'\n",
    "    pvalue = stats.levene(np.array(riquezas)[het, :, 0],\n",
    "                      np.array(riquezas)[het, :, 1],\n",
    "                      np.array(riquezas)[het, :, 2],\n",
    "                      np.array(riquezas)[het, :, 3],\n",
    "                      np.array(riquezas)[het, :, 4],\n",
    "                      np.array(riquezas)[het, :, 5],\n",
    "                      np.array(riquezas)[het, :, 6],\n",
    "                      np.array(riquezas)[het, :, 7],\n",
    "                      np.array(riquezas)[het, :, 8],\n",
    "                      np.array(riquezas)[het, :, 9], center='median')[1]\n",
    "    if pvalue <=0.05:\n",
    "        equal_std = '---std NOT EQUAL---'\n",
    "    print('h{}, pvalue={:.3f}, {}'.format(het, pvalue, equal_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?stats.kruskal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
